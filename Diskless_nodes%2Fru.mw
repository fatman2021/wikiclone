<languages />

{{Metadata|abstract=Данная статья поможет вам создавать бездисковые станции под управлением Gentoo Linux}}

Это HOWTO поможет Вам создать и настроить бездисковые рабочие станции с Gentoo Linux.

== Введение ==

=== Об этом руководстве ===

Это руководство поможет Вам настроить ''бездисковые'' рабочие станции основанные на дистрибутиве Gentoo Linux. Мы стремимся сделать это руководство настолько удобным для пользователя, насколько возможно, и также, ориентированным на новичка в Linux, (потому что каждый из нас был новичком в какой-то момент :) В то время как опытные пользователи могут с легкостью объединить множество доступных руководств по бездисковым станциям и сетям вместе, мы надеемся, что это руководство сможет облегчить установку для всех заинтересованных пользователей, независимо от того, гики они или нет. 

=== Что такое бездисковая машина? ===

Бездисковая машина - это компьютер без каких-либо обычных загрузочных устройств, таких как жесткие диски, дискеты, или оптические диски. Бездисковые станции загружаются по сети и требуют сервер, который обеспечит их местом для хранения данных, как это сделал бы локальный жесткий диск. С этого момента, мы будем называть сервер ведущим устройством - ''master'', в то время как бездисковая машина будет ведомым устройством - ''slave''. Ведомый узел требует сетевую плату с поддержкой загрузки PXE или Etherboot; проверьте поддерживаемый список по адресу [http://www.etherboot.org Etherboot.org]. Большинство современных плат поддерживает PXE, множество встроенных в материнскую плату сетевых плат также будут работать. 

=== Перед тем как начать ===

Вам необходимо установить Gentoo на master-узел и иметь достаточно пространства на master-узле, чтобы хранить файловые системы slave-узлов. Также, удостоверьтесь, что вы имеете один из интерфейсов подключения к интернету отдельно от подключения к локальной сети. 

== Конфигурация ведущего и ведомых компьютеров ==

=== Информация о ядрах ===

Ядро - это программа, которая располагается между аппаратным обеспечением и всеми остальными программами, которые загружены на Вашу машину. По существу, это сердце операционной системы, включающей в себя ядро. Когда компьютер загружается, BIOS выполняет инструкции, найденные в зарезервированном загрузочном пространстве жесткого диска. Эти инструкции обычно являются загрузчиком, который загружает ядро. После того, как ядро загружено, все процессы управляются им. 

Чтобы найти больше информации по ядрам и их настройке, Вы можете проверить [http://www.tldp.org/HOWTO/Kernel-HOWTO.html kernel HOWTO] . 

=== Конфигурация ядра на ведущем компьютере ===

Ядро ведущей машины может быть настолько большим и настроенным под Ваши нужды, насколько Вы захотите. Но в то же время, существует несколько требуемых параметров ядра, которые Вам необходимо выбрать. Перейдете в меню конфигурации ядра, введя: 

{{RootCmd|cd /usr/src/linux
|make menuconfig}}

Вы должны получить графический интерфейс, серого и синего цвета, который предлагает безопасную альтернативу редактированию файла {{Path|/usr/src/linux/.config}} вручную. Если ядро в данный момент функционирует нормально, Вы можете сохранить текущий файл конфигурации, выйдя из графического интерфейса и введя следующую команду: 

{{RootCmd|cp .config .config_working}}

Перейдите в следующие подменю и убедитесь, что перечисленные элементы меню отмечены как встроенные в ядро - built-in (а ''не как'' модули - modular). Параметры, показанные ниже, взяты из ядра версии 2.6.10. Если Вы используете другую версию, текст, или последовательность элементов меню может различаться. Просто убедитесь, что Вы, по меньшей мере, выбрали те элементы, которые показаны ниже. 

{{Kernel/ru|Параметры ядра на ведущей системе|<pre>
Code maturity level options  --->
  [*] Prompt for development and/or incomplete code/drivers
  
Device Drivers --->
  Networking options --->
    <*> Packet socket
    <*> Unix domain sockets
    [*] TCP/IP networking
    [*]   IP: multicasting
    [ ] Network packet filtering (replaces ipchains)
  
File systems --->
  Network File Systems  --->
    <*> NFS server support
    [*]   Provide NFSv3 server support
</pre>}}

Если Вы хотите получить доступ к интернету на master-узле и/или настроить безопасный межсетевой экран, убедитесь, что Вы добавили поддержку iptables:

{{Kernel/ru|Включение поддержки iptables|<pre>
  [*] Network packet filtering (replaces ipchains)
  IP: Netfilter Configuration  --->
    <*> Connection tracking (required for masq/NAT)
    <*> IP tables support (required for filtering/masq/NAT)
</pre>
}}

Если Вы хотите использовать пакетную фильтрацию, Вы можете включить оставшиеся параметры в качестве модулей позже. Чтобы узнать о том, как настроить их должным образом, прочтите [http://www.gentoo.org//doc/en/security/security-handbook.xml?part=1&chap=12 Главу настольной книги по безопасности Gentoo, посвященную межсетевым экранам] . 

{{Note/ru|Эти параметры конфигурации ядра должны быть добавлены только к параметрам конфигурации, характерным для системы, и не предназначены для того, чтобы полностью заменить собой настройки ядра.}}

После того, как Вы переконфигуровали ядро на master-узле, его нужно собрать заново: 

{{RootCmd|make && make modules_install
|cp arch/i386/boot/bzImage /boot/bzImage-master}}

Затем, добавьте запись для нового ядра в {{Path|lilo.conf}} или {{Path|grub.conf}}, в зависимости от используемого загрузчика, и сделайте новое ядро ядром, загружаемым по умолчанию. Теперь когда новый файл bzImage скопирован в загрузочный каталог, все, что требуется сделать - перезагрузить систему чтобы активировать новые параметры. 

=== Настройки ведомого ядра ===

Рекомендуется, чтобы ведомое ядро было собрано без модулей, так как их загрузка и настройка в случае удаленной загрузки ядра - сложный и ненужный процесс. Вдобавок, ведомое ядро должно быть настолько маленьким и компактным, насколько это возможно, чтобы эффективно загрузиться по сети. Мы будем компилировать ведомое ядро в том же месте, где было сконфигурировано ведущее. 

Во избежание путаницы и пустой траты времени, возможно, неплохой идеей является сделать резервное копирование файла конфигурации ведущего ядра вводом следующих команд: 

{{RootCmd|cp /usr/src/linux/.config /usr/src/linux/.config_master}}

А сейчас, нам потребуется сконфигурировать ведомое ядро тем же образом, каким мы конфигурировали ведущее. Если Вы хотите начать со свежего файла конфигурации, Вы всегда можете восстановить файл по умолчанию {{Path|/usr/src/linux/.config}} , введя: 

{{RootCmd|cd /usr/src/linux
|cp .config_master .config}}

Теперь, перейдите в графический интерфейс конфигурации вводом следующей команды: 

{{RootCmd|cd /usr/src/linux
|make menuconfig}}

Вам будет необходимо удостовериться, что Вы выбрали следующие параметры как встроенные, а ''не как'' модули ядра: 

{{Kernel/ru|Параметры ведомого ядра|<pre>
Code maturity level options  --->
  [*] Prompt for development and/or incomplete code/drivers
  
Device Drivers --->
  [*] Networking support
  Networking options --->
    <*> Packet socket
    <*> Unix domain sockets
    [*] TCP/IP networking
    [*]   IP: multicasting
    [*]   IP: kernel level autoconfiguration
    [*]     IP: DHCP support (NEW)
  
File systems --->
  Network File Systems  --->
    <*> file system support
    [*]   Provide NFSv3 client support
    [*]   Root file system on NFS
</pre>
}}

{{Note/ru|Альтернативой dhcp-серверу является настройка BOOTP сервера.}}

{{Important/ru|Важно, чтобы Вы добавили поддержку вашей сетевой платы в ядро (не как модуль) на узлах. Однако, использование модулей, в основном, не является проблемой для бездисковых машин.}}

Теперь необходимо собрать ведомое ядро. Вам надо действовать осторожно, чтобы не повредить какие-либо модули ядра, которые Вы собрали для ведущей машины: 

{{RootCmd|cd /usr/src/linux
|make}}

Теперь, создайте каталог на master-узле, который будет использован для хранения файлов slave-узлов и требуемых системных файлов. Мы используем каталог {{Path|/diskless}}, но Вы можете выбрать любое место, которое хотите. Теперь, скопируйте bzImage для ведомых компьютеров в каталог {{Path|/diskless}} : 


{{Note/ru|Если Вы используете разные архитектуры, Вы можете сохранить каждый файл конфигурации в соответствующий файл {{Path|.config_arch}} . Проделайте то же самое с образами ядра: сохраните их в каталог {{Path|/diskless}} как разные файлы, названные в соответствии с архитектурой ядра - {{Path|bzImage_arch}} .}}


{{RootCmd|mkdir /diskless
|cp /usr/src/linux/arch/i386/boot/bzImage /diskless}}

=== Конфигурация предварительных файловых систем для slave-узлов ===

Файловые системы для систем master и slave могут быть отрегулированы и изменены в значительной степени. На данный момент мы заинтересованы только в том, как получить предварительную файловую систему с подходящими файлами конфигурации и точками монтирования. Во-первых, мы должны создать каталог внутри {{Path|/diskless}} для первой slave-системы. Каждая slave-система требует свою собственную корневую файловую систему, потому что общий доступ к определенным системным файлам вызовет проблемы с разрешениями и сбои. Вы можете назвать эти каталоги как хотите, но я предполагаю использование IP-адресов slave-машин, так как они уникальны и не могут быть перепутаны. Например, пусть статический IP нашей первой slave-машины будет следующим:
<code>192.168.1.21</code> : 

{{RootCmd|mkdir /diskless/192.168.1.21}}

Различные файлы конфигурации в каталоге {{Path|/etc}} нуждаются в изменении для того, чтобы работать на slave-узле. Скопируйте каталог {{Path|/etc}} master-узла в корневой каталог slave-узла, введя: 

{{RootCmd|cp -r /etc /diskless/192.168.1.21/etc}}

Все же, эта файловая система пока не готова, потому что ей требуются разные точки монтирования и каталоги. Чтобы их создать, введите: 

{{RootCmd|mkdir /diskless/192.168.1.21/home
|mkdir /diskless/192.168.1.21/dev
|mkdir /diskless/192.168.1.21/proc
|mkdir /diskless/192.168.1.21/tmp
|mkdir /diskless/192.168.1.21/mnt
|chmod a+w /diskless/192.168.1.21/tmp
|mkdir /diskless/192.168.1.21/mnt/.initd
|mkdir /diskless/192.168.1.21/root}}

{{RootCmd|mkdir /diskless/192.168.1.21/sys
|mkdir /diskless/192.168.1.21/var
|mkdir /diskless/192.168.1.21/var/empty
|mkdir /diskless/192.168.1.21/var/lock
|mkdir /diskless/192.168.1.21/var/log
|mkdir /diskless/192.168.1.21/var/run
|mkdir /diskless/192.168.1.21/var/spool
|mkdir /diskless/192.168.1.21/usr
|mkdir /diskless/192.168.1.21/opt
}}

Большинство из этих ''файлов-заглушек'' должно быть Вам знакомо; такие заглушки как {{Path|/dev}} , {{Path|/proc}} или {{Path|/sys}} будут заполнены при запуске slave-узла, остальные будут примонтированы позже. Вам также нужно изменить файл {{Path|/diskless/192.168.1.21/etc/conf.d/hostname}} , чтобы отобразить имя хоста slave-узла. Двоичные файлы, библиотеки и другие файлы будут заполнены позже в этом руководстве, прямо перед тем, как мы попытаемся загрузить slave-узел. 

Даже хотя каталог {{Path|/dev}} и заполняется менеджером устройств <code>udev</code> позже, Вам требуется создать файл {{Path|console}} . Если Вы этого не сделаете, Вы получите ошибку ''unable to open initial console''. 

{{RootCmd|mknod /diskless/192.168.1.21/dev/console c 5 1}}

== Конфигурация DHCP-сервера ==

=== Информация о DHCP-сервере ===

DHCP означает Dynamic Host Configuration Protocol (протокол динамической настройки узла). DHCP-сервер - это первый компьютер с которым будут соединяться slave-узлы при PXE-загрузке. Основной целью DHCP-сервера является назначение IP-адресов. DHCP-сервер может назначать IP-адреса, основываясь на MAC-адресах сети на основе ethernet. Как только slave-узел получит IP-адрес, DHCP-сервер сообщит этому компьютеру где можно получить его первичную файловую систему и ядро. 

=== Перед тем как начать ===

Перед тем как Вы начнете, проверьте что работает несколько вещей. Во-первых, проверьте соединение с сетью: 

{{RootCmd|ifconfig eth0 multicast
|ifconfig -a}}

Вам также необходимо убедиться, что работает устройство ''eth0''. Оно должно выглядеть следующим образом: 

{{Code/ru|Устройство eth0, работающее должным образом|<pre>
eth0      Link encap:Ethernet  HWaddr 00:E0:83:16:2F:D6
          inet addr:192.168.1.1  Bcast:192.168.1.255  Mask:255.255.255.0
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:26460491 errors:0 dropped:0 overruns:2 frame:0
          TX packets:32903198 errors:0 dropped:0 overruns:0 carrier:1
          collisions:0 txqueuelen:100
          RX bytes:2483502568 (2368.4 Mb)  TX bytes:1411984950 (1346.5 Mb)
          Interrupt:18 Base address:0x1800
</pre>
}}

Важно, чтобы оно выводило ''MULTICAST''. Если это не так, Вы должны собрать ядро заново, чтобы включить поддержку multicast.

=== Установка DHCP-сервера ===

Если Ваша сеть еще не имеет установленного DHCP-сервера, Вам придется его установить: 

{{Emerge|dhcp}}

Если DHCP-сервер уже присутствует в сети, Вам потребуется отредактировать файл конфигурации для корректной загрузки компьютера по сети с помощью PXE. 

=== Конфигурация DHCP-сервера ===

Вам надо отредактировать только один конфигурационный файл перед запуском DHCP-сервера: {{Path|/etc/dhcp/dhcpd.conf}} . Скопируйте и отредактируйте предусмотренный файл-образец: 

{{RootCmd|cp /etc/dhcp/dhcpd.conf.sample /etc/dhcp/dhcpd.conf
|nano -w /etc/dhcp/dhcpd.conf}}

Основная схема этого файла задана в виде отступов и выглядит следующим образом: 

{{Code/ru|Образец схемы файла dhcpd.conf|<pre>
# глобальные параметры
ddns-update-style none;
shared-network LOCAL-NET {
  # параметры shared network
  subnet 192.168.1.0 netmask 255.255.255.0 {
    # параметры subnet network
    host slave{
        # параметры, относящиеся к хосту
    }
    group {
        # параметры, относящиеся к группе
    }
  }
}
</pre>
}}

Раздел <code>shared-network</code> - необязательный и должен использоваться для назначаемых Вами IP-адресов, которые принадлежат к одной и той же топологии сети. По крайней мере, должен быть объявлен один раздел <code>subnet</code>, а необязательный раздел <code>group</code> позволяет группировать параметры между элементами. Хороший пример файла {{Path|dhcpd.conf}} выглядит так: 

{{Code/ru|Образец файла dhcpd.conf|<pre>
#
# Образец файла dhcpd.conf для бездисковых клиентов
#
  
# Отключение динамической DNS
ddns-update-style none;
  
# Предположим, достаточно одного шлюза по умолчанию
option routers 192.168.1.1;
  
# Предоставление DNS-информации клиентам
option domain-name-servers 192.168.1.1;
option domain-name "mydomain.com";
  
# Указание используемого TFTP-сервера
next-server 192.168.1.1;
  
# Объявление вендор-зависимого буфера параметров для клиентов PXE:
# Code 1: Групповой (multicast) IP-адрес загрузочного файлового сервера
# Code 2: UDP-порт, отслеживаемый клиентом для MTFTP-ответов
# Code 3: UDP-порт, используемый MTFTP-серверами для прослушивания MTFTP-запросов
# Code 4: Количество секунд, в течение которого клиент должен ожидать каких-либо действий,
#         перед тем, как начать новую MTFTP-передачу
# Code 5: Количество секунд, в течение которого клиент должен ожидать, перед перезапуском
#         MTFTP-передачи
  
option space PXE;
option PXE.mtftp-ip               code 1 = ip-address;
option PXE.mtftp-cport            code 2 = unsigned integer 16;
option PXE.mtftp-sport            code 3 = unsigned integer 16;
option PXE.mtftp-tmout            code 4 = unsigned integer 8;
option PXE.mtftp-delay            code 5 = unsigned integer 8;
option PXE.discovery-control      code 6 = unsigned integer 8;
option PXE.discovery-mcast-addr   code 7 = ip-address;
  
# Определите подсеть для размещения бездисковых рабочих станций
subnet 192.168.1.0 netmask 255.255.255.0 {
  
  # Предоставление PXE-клиентам необходимой информации
  class "pxeclient" {
    match if substring(option vendor-class-identifier, 0, 9) = "PXEClient";
    vendor-option-space PXE;
  
    # Должен быть настроен по меньшей мере один из вендор-зависимых PXE-параметров
    # для того, чтобы загрузочные ПЗУ клиента - boot ROMs - располагали информацией, о том, что этот сервер PXE-совместим.
    # Мы устанавливаем MCAST IP-адрес в значение 0.0.0.0 чтобы сообщить boot ROM
    # что мы не можем предоставить групповой TFTP.
  
    option PXE.mtftp-ip 0.0.0.0;
  
    # Это имя файла, который должны загрузить загрузочные ПЗУ - boot ROMs.
    filename "pxelinux.0";
  }
  
  # Предоставьте необходимую информацию Etherboot-клиентам
  class "etherboot" {
    match if substring(option vendor-class-identifier, 0, 9) = "Etherboot";
    filename "vmlinuz_arch";
  }
  
  # Добавьте одно объявление хоста для каждой бездисковой рабочей станции
  host slave21 {
    hardware ethernet 00:02:A5:04:3B:66;
    fixed-address 192.168.1.21;
  }
}
</pre>
}}

{{Note/ru|Ничто не запрещает использовать PXE boot и Etherboot вместе. Листинг кода, приведенный выше, просто является примером; если у Вас возникли проблемы, пожалуйста, проконсультируйтесь с документацией DHCPd.}}

С IP-адреса после <code>next-server</code> будет запрошен указанный <code>filename</code>. Этот IP-адрес должен быть IP-адресом tftp-сервера, обычно тем же самым, что и IP-адрес master-узла. <code>filename</code> является путем относительно каталога {{Path|/diskless}} (вследствие того, что параметры, относящиеся к tftp-серверу будут рассмотрены позже). Внутри раздела <code>host</code>, параметр <code>hardware ethernet</code> указывает MAC-адрес, а <code>fixed-address</code> назначает фиксированный IP-адрес для этого отдельного MAC-адреса. Существует достаточно хорошая man-страница по {{Path|dhcpd.conf}} с параметрами, которые не рассмотрены в этом HOWTO. Вы можете прочитать ее, введя: 

{{Cmd|man dhcpd.conf}}

=== Запуск DHCP-сервера ===

Перед тем как Вы запустите сценарий инициализации dhcp, отредактируйте файл {{Path|/etc/conf.d/dhcp}}, так, чтобы он выглядел следующим образом: 

{{Code/ru|Образец /etc/conf.d/dhcp|<pre>
IFACE="eth0"
# Добавьте любые индивидуальные настройки по необходимости
</pre>
}}

Переменная <code>IFACE</code> - это устройство, на котором необходимо запустить DHCP-сервер. В нашем случае это <code>eth0</code>. Добавление большего количества аргументов к переменной <code>IFACE</code> может быть полезно в случае сложной топологии сети с большим количеством Ethernet-адаптеров. Чтобы запустить dhcp-сервер, введите: 

{{RootCmd|/etc/init.d/dhcp start}}

Чтобы добавить dhcp-сервер к сценариям иницализации, введите: 

{{RootCmd|rc-update add dhcp default}}

=== Устранение неполадок, связанных с DHCP-сервером ===

Чтобы проверить загружается ли узел сети, посмотрите сообщения в {{Path|/var/log/messages}} . Если узел загружается успешно, файл {{Path|messages}} должен содержать внизу несколько строчек, выглядящих следующим образом: 

{{Code/ru|Образец записей лог-файла, созданных dhcp|<pre>
DHCPDISCOVER from 00:00:00:00:00:00 via eth0
DHCPOFFER on 192.168.1.21 to 00:00:00:00:00:00 via eth0
DHCPREQUEST for 192.168.1.21 from 00:00:00:00:00:00 via eth0
DHCPACK on 192.168.1.21 to 00:00:00:00:00:00 via eth0
</pre>
}}

{{Note/ru|Этот лог-файл может также помочь в обнаружении MAC-адресов slave-узлов.}}

Если Вы получаете следущее сообщение, это возможно означает, что с файлом конфигурации что-то не то, но в то же время DHCP-сервер передает данные верно. 

{{Code/ru|Образец ошибки сервера dhpc|<pre>
no free leases on subnet LOCAL-NET
</pre>
}}

Каждый раз после изменения файла конфигурации Вы должны перезапустить DHCP-сервер. Чтобы перезапустить сервер, введите: 

{{RootCmd|/etc/init.d/dhcpd restart}}

== Настройка TFTP-сервера и PXE загрузчика Linux и/или Etherboot ==

=== Информация о TFTP-сервере ===

TFTP означает простой протокол передачи файлов (англ. Trivial File Transfer Protocol). TFTP-сервер предоставит ведомым компьютерам ядра и первичную файловую систему для начальной загрузки. Все ядра и файловые системы ведомых машин будут храниться на TFTP-сервере, поэтому, хорошей идеей будет сделать master-узел TFTP-сервером. 

=== Установка TFTP-сервера ===

Высоко рекомендуемый tftp-сервер доступен в качестве пакета tftp-hpa. Этот tftp-сервер написан автором SYSLINUX и очень хорошо работает с pxelinux. Чтобы его установить, просто введите: 

{{Emerge|tftp-hpa}}

=== Настройка TFTP-сервера ===

Отредактируйте файл {{Path|/etc/conf.d/in.tftpd}} . Вам необходимо указать каталог tftproot в <code>INTFTPD_PATH</code> и также, любые параметры командной строки в <code>INTFTPD_OPTS</code> . Это должно выглядеть следующим образом: 

{{Code/ru|Образец файла /etc/conf.d/in.tftpd|<pre>
INTFTPD_PATH="/diskless"
INTFTPD_OPTS="-l -v -s ${INTFTPD_PATH}"
</pre>
}}

Параметр <code>-l</code> обозначает то, что сервер слушает в автономном режиме (stand alone mode), поэтому Вам нет необходимости запускать inetd. <code>-v</code> означает, что уровень вывода сообщений log/error должен быть избыточным. <code>-s /diskless</code> указывает на корневой каталог tftp-сервера.

=== Запуск TFTP-сервера ===

Чтобы запустить tftp-сервер, введите: 

{{RootCmd|/etc/init.d/in.tftpd start}}

Эта команда должна запустить tftp-сервер с параметрами, которые Вы указали в {{Path|/etc/conf.d/in.tftpd}} . Если Вы хотите чтобы этот сервер автоматически запускался во время загрузки, наберите: 

{{RootCmd|rc-update add in.tftpd default}}

=== Информация о PXELINUX ===

Этот раздел не требуется если Вы пользуетесь только Etherboot. PXELINUX - это сетевой загрузчик, эквивалентный LILO или GRUB, который обслуживается через TFTP. По существу, это небольшой набор инструкций, который сообщает клиенту где разместить его ядро и временную файловую систему и разрешает различные параметры ядра. 

=== Перед тем как Вы начнете ===

Вам необходим файл pxelinux.0, который поставляется с пакетом SYSLINUX от H. Peter Anvin. Вы можете установить этот пакет следующей командой: 

{{Emerge|syslinux}}

=== Настройка PXELINUX ===

{{Note/ru|Это не требуется для Etherboot}}

Перед тем как Вы запустите tftp-сервер Вам необходимо настроить pxelinux. Сначала, скопируйте двоичный файл pxelinux в каталог {{Path|/diskless}}: 

{{RootCmd|cp /usr/share/syslinux/pxelinux.0 /diskless
|mkdir /diskless/pxelinux.cfg
|touch /diskless/pxelinux.cfg/default}}

Это создаст файл конфигурации загрузчика по умолчанию. Двоичный файл {{Path|pxelinux.0}} просматривает каталог {{Path|pxelinux.cfg}} в поисках файла с таким же именем, как и IP-адрес клиента в шестнадцатеричной системе. Если он не находит этот файл, он убирает самую правую цифру из имени файла и продолжает поиск, пока цифры не закончатся. Версии syslinux 2.05 и более поздние сперва выполнят поиск файла с таким же именем, как и MAC-адрес. Если таких файлов не найдено, начинается поиск по алгоритму, описанному выше. Если ничего не найдено, используется файл {{Path|default}} . 

{{Code/ru|Файлы, которые ищет PXE в каталоге pxelinux.cfg/,по порядку|<pre>
## (01 в начале означает Ethernet, следующие байты соответствуют MAC-адресу slave-узла)
01-00-40-63-c2-ca-c9
  
## (Assigned IP in hexadecimal)
C0A80115
C0A8011
C0A801
C0A80
C0A8
C0A
C0
C
  
default
</pre>
}}

{{Note/ru|Все буквы являются строчными.}}

Давайте начнем с файла {{Path|default}}: 

{{Code/ru|Образец файла pxelinux.cfg/default|<pre>
DEFAULT /bzImage
APPEND ip=dhcp root=/dev/nfs nfsroot=192.168.1.1:/diskless/192.168.1.21
</pre>
}}

Ярлык <code>DEFAULT</code> указывает pxelinux на ядро bzImage, которое мы собрали ранее. Ярлык <code>APPEND</code> добавляет параметры инициализации ядра. Так как мы собрали ведомое ядро с параметром  <code>NFS_ROOT_SUPPORT</code> , мы указываем nfsroot здесь. Первый IP - IP-адрес ведущего компьютера, а второй IP - это каталог, который был создан в каталоге {{Path|/diskless}} для хранения первичной системы ведомого компьютера. 

=== Информация об Etherboot ===

{{Note/ru|Это не требуется, если Вы используете PXE boot.}}

Etherboot загружает загрузочные образы (boot images) с сервера TFTP. Как и PXE, он эквивалентен LILO или GRUB. Утилита <code>mknbi</code> позволяет Вам создавать разные образы с использованием различных параметров. 

=== Перед тем как Вы начнете ===

Вам потребуется установить пакет <code>mknbi</code> (утилиту для того, чтобы сделать отмеченные образы ядра пригодными для сетевой загрузки), чтобы создать образы Etherboot. Этот инструмент создаст заранее настроенный образ ядра из Вашего первоначального ядра. Он содержит параметры загрузки, как показано в дальнейшем. 

{{Emerge|mknbi}}

=== Настройка Etherboot ===

В этом разделе мы создадим простой образ etherboot. Так как dhcp-сервер объявляет путь к корневому каталогу на клиентах в строке "option root-path" файла dhcp.conf, нам не требуется включать его здесь. Больше подробностей можно найти в руководстве mknbi. 

{{Cmd|man mknbi}}

Создание загрузочных образов. Это создаст загружаемый образ системы в формате ELF, способный передать ядру dhcp и путь к корневому каталогу. Это также заставит ядро просмотреть сеть в поисках dhcp-сервера. 

{{RootCmd|mkelf-linux -ip{{=}}dhcp /diskless/bzImage > /diskless/vmlinuz }}

{{Note/ru|Для архитектурно-зависимых образов Вам необходимо ввести <code>bzImage_arch</code> и <code>vmlinuz_arch</code> .}}

=== Устранение неполадок в процессе сетевой загрузки ===

Существует несколько вещей, которые Вы можете использовать для отладки процесса загрузки по сети. Прежде всего, Вы можете воспользоваться инструментом <code>tcpdump</code> . Чтобы установить <code>tcpdump</code> , введите: 

{{Emerge|tcpdump}}

Теперь Вы можете прослушивать различный сетевой трафик и убедиться в том, что происходит взаимодействие между клиентом и сервером. Если что-либо не работает, есть несколько вещей, которые нужно проверить. Во-первых, убедитесь, что клиент и сервер подсоединены физически должным образом и что сетевые кабели не повреждены. Если клиент/сервер не получают запросы на отдельный порт убедитесь, что межсетевой экран не является помехой. Чтобы просмотреть взаимодействие между двумя компьютерами, введите: 

{{RootCmd|tcpdump host client_ip and server_ip}}

Вы также можете использовать <code>tcpdump</code> для того, чтобы прослушать отдельный порт, такой как, например, tftp-порт, введя: 

{{RootCmd|tcpdump port 69}}

Распространенной ошибкой, которую Вы можете получить, является: "PXE-E32: TFTP open time-out". Возможно, это связано с проблемами с межсетевым экраном. Если Вы используете <code>TCPwrappers</code> , Вы могли бы проверить {{Path|/etc/hosts.allow}} и {{Path|etc/hosts.deny}} и убедиться, что они сконфигурированы должным образом. Клиенту должно быть разрешено подключение к серверу.

== Конфигурация NFS-сервера ==

=== Информация об NFS-сервере ===

NFS означает Network File System - протокол сетевого доступа к файловым системам. NFS-сервер будет использоваться для предоставления директорий slave-узлу. Эта часть может быть, в каком-то смысле, настроена под ваши нужды позже, но прямо сейчас все что нам нужно - это предварительный ведомый узел для бездисковой загрузки. 

=== Информация о Portmapper ===

Различные клиент-серверные службы не слушают отдельный порт, но, вместо этого, полагаются на RPCs (Remote Procedure Calls - удаленный вызов процедур). Когда сервис инициализируется, он прослушивает случайный порт, и затем регистрирует этот порт с помощью утилиты Portmapper. NFS полагается на RPCs и, таким образом, требует того, чтобы Portmapper был запущен перед ее запуском. 

=== Перед тем как Вы начнете ===

NFS-сервер требует поддержку со стороны ядра, поэтому, если ее нет, Вы должны собрать ядро master-узла заново. Чтобы дважды проверить конфигурацию ядра master-системы, введите: 

{{RootCmd|grep NFS /usr/src/linux/.config_master}}

Вы должны получить результат, который будет выглядеть следующим образом, если ядро сконфигурировано правильно: 

{{Kernel/ru|Правильные параметры, относящиеся к NFS, в конфигурации ядра ведущей системы|<pre>
CONFIG_PACKET=y
# CONFIG_PACKET_MMAP is not set
# CONFIG_NETFILTER is not set
CONFIG_NFS_FS=y
CONFIG_NFS_V3=y
# CONFIG_NFS_V4 is not set
# CONFIG_NFS_DIRECTIO is not set
CONFIG_NFSD=y
CONFIG_NFSD_V3=y
# CONFIG_NFSD_V4 is not set
# CONFIG_NFSD_TCP is not set
</pre>
}}

=== Установка NFS-сервера ===

Пакет NFS может быть установлен с помощью системы Portage, посредством ввода: 

{{Emerge|nfs-utils}}

Этот пакет установит утилиту для проброса портов (portmapping utility), nfs-сервер, и утилиты nfs-клиентов, а также автоматически обработает зависимости инициализации. 

== Настройка NFS-сервера ==

Вам придется отредактировать три основных файла конфигурации: 

{{Code/ru|Файлы конфигурации Nfs|<pre>
/etc/exports
/diskless/192.168.1.21/etc/fstab
/etc/conf.d/nfs
</pre>
}}

Файл {{Path|/etc/exports}} указывает как, кому и что можно экспортировать через NFS. Файл fstab slave-узла будет изменен таким образом, чтобы было можно примонтировать файловые системы NFS, экспортируемые master-узлом. 

Обычный файл {{Path|/etc/exports}} для master-узла должен выглядеть следующим образом: 

{{Code/ru|Образец файла /etc/exports на master-узле|<pre>
# одна строка, подобная этой, должна присутствовать на каждом из slave-узлов
/diskless/192.168.1.21   192.168.1.21(sync,rw,no_root_squash,no_all_squash)
# общие параметры для всех slave-узлов
/opt   192.168.1.0/24(sync,ro,no_root_squash,no_all_squash)
/usr   192.168.1.0/24(sync,ro,no_root_squash,no_all_squash)
/home  192.168.1.0/24(sync,rw,no_root_squash,no_all_squash)
# если Вам потребуется общий log-файл
/var/log   192.168.1.21(sync,rw,no_root_squash,no_all_squash)
</pre>
}}

Первое поле обозначает каталог для экспорта, а следующее за ним поле указывает, кому и как надо передать содержащуюся в нем информацию. Это поле может быть поделено на две части: кому разрешено монтировать этот отдельный каталог, и что монтирующий этот каталог клиент может делать с файловой системой: <code>ro</code> - доступ только для записи, <code>rw</code> - для чтения/записи; параметры <code>no_root_squash</code> и <code>no_all_squash</code> являются важными для бездисковых клиентов, которые осуществляют запись на диск, так чтобы они не были "сброшены" механизмом ограничения прав доступа root squash при I/O запросах. Файл fstab на ведомом узле, {{Path|/diskless/192.168.1.21/etc/fstab}} , должен выглядеть так: 

{{Code/ru|Образец файла fstab на slave-узле|<pre>
# эти записи необходимы
master:/diskless/192.168.1.21   /         nfs     sync,hard,intr,rw,nolock,rsize=8192,wsize=8192    0 0
master:/opt                     /opt      nfs     sync,hard,intr,ro,nolock,rsize=8192,wsize=8192    0 0
master:/usr                     /usr      nfs     sync,hard,intr,ro,nolock,rsize=8192,wsize=8192    0 0
master:/home                    /home     nfs     sync,hard,intr,rw,nolock,rsize=8192,wsize=8192    0 0
none                            /proc     proc    defaults                                     0 0
# полезно, но является избыточным
master:/var/log                 /var/log  nfs     hard,intr,rw                                 0 0
</pre>
}}

В этом примере, ''master'' - это просто имя хоста ведущего узла, но оно также запросто может быть его IP-адресом. Первое поле обозначает каталог, который необходимо примонтировать, а второе поле указывает на место, куда он должен быть примонтирован. Третье поле описывает файловую систему и должно содержать NFS для любого монтируемого каталога с NFS. Четвертое поле обозначает различные параметры, которые будут использованы в процессе монтирования (смотри mount(1), для информации по параметрам монтирования). Некоторые люди имели проблемы с режимом монтирования soft mount, поэтому мы сделали режим hard mount, но Вам следует просмотреть различные параметры в {{Path|/etc/fstab}}, чтобы сделать Ваш кластер более эффективным. 

Последний файл, который необходимо отредактировать - это файл {{Path|/etc/conf.d/nfs}}, который описывает несколько параметров для nfs при инициализации. Он выглядит так: 

{{Code/ru|Образец файла /etc/conf.d/nfs на master-узле|<pre>
# Файл конфигурации для /etc/init.d/nfs
  
# Количество серверов для запуска по умолчанию
RPCNFSDCOUNT=8
  
# Параметры для передачи в rpc.mountd
RPCMOUNTDOPTS=""
</pre>
}}

Вам следует изменить переменную <code>RPCNFSDCOUNT</code> на количество бездисковых рабочих станций в сети. 

=== Запуск NFS-сервера ===

Вам следует запустить nfs-сервер вместе с его сценарием инициализации, расположенным в каталоге {{Path|/etc/init.d}} , введя команду: 

{{RootCmd|/etc/init.d/nfs start}}

Если Вы хотите, чтобы этот сценарий запускался при загрузке системы, просто введите: 

{{RootCmd|rc-update add nfs default}}

== Завершение построения файловой системы на slave-узлах ==

=== Копирование недостающих файлов ===

Теперь мы синхронизируем файловую систему на slave-узлах с файловой системой master-узла и предоставим необходимые двоичные файлы. При этом, мы сохраним файлы, характерные для slave-узлов. 

{{RootCmd|rsync -avz /bin /diskless/192.168.1.21
|rsync -avz /sbin /diskless/192.168.1.21
|rsync -avz /lib /diskless/192.168.1.21}}

{{Note/ru|Причиной, по которой используется команда rsync -avz вместо cp, является сохранение символьных ссылок и разрешений.}}

=== Настройки сети на бездисковых машинах ===

Для того, чтобы предотвратить сценарий инициализации сети от завершения соединения с NFS-сервером, Вам необходимо добавить следующий параметр в файл {{Path|/etc/conf.d/net}} на файловых системах бездисковых клиентов. 

{{Code/ru|Редактирование /etc/conf.d/net|<pre>
config_eth0=( "noop" )
</pre>
}}

{{Note/ru|Чтобы получить больше информации, пожалуйста, прочитайте {{Path|/usr/share/doc/openrc-*/net.example.bz2}} .}}

=== Сценарии инициализации ===

Вам необходимо столько же сценариев инициализации в каталоге {{Path|/diskless/192.168.1.21/etc/runlevels}} , сколько сервисов Вам требуется на Ваших бездисковых рабочих станциях. Все это зависит от того, что Вам требуется от ведомых станций. 

{{Warning/ru|Не используйте программу <code>rc-update</code> чтобы добавить или удалить сценарии из уровней выполнения slave-узлов, когда Вы зашли на master-узел. Это изменит уровни выполнения на master-узле. Вам потребуется создать ссылки вручную или войти на ведомые рабочие станции, используя ssh или подсоединить экран и клавиатуру к ведомому компьютеру.}}

{{Code/ru|Обычные уровни выполнения ведомых рабочих станций|<pre>
/diskless/192.168.1.21/etc/runlevels/:
total 16
drwxr-xr-x    2 root     root         4096 2003-11-09 15:27 boot
drwxr-xr-x    2 root     root         4096 2003-10-01 21:10 default
drwxr-xr-x    2 root     root         4096 2003-03-13 19:05 nonetwork
drwxr-xr-x    2 root     root         4096 2003-02-23 12:26 single
  
/diskless/192.168.1.21/etc/runlevels/boot:
total 0
lrwxrwxrwx    1 root     root           20 2003-10-18 17:28 bootmisc -> /etc/init.d/bootmisc
lrwxrwxrwx    1 root     root           19 2003-10-18 17:28 checkfs -> /etc/init.d/checkfs
lrwxrwxrwx    1 root     root           17 2003-10-18 17:28 clock -> /etc/init.d/clock
lrwxrwxrwx    1 root     root           22 2003-10-18 17:28 domainname -> /etc/init.d/domainname
lrwxrwxrwx    1 root     root           20 2003-10-18 17:28 hostname -> /etc/init.d/hostname
lrwxrwxrwx    1 root     root           22 2003-10-18 17:28 localmount -> /etc/init.d/localmount
lrwxrwxrwx    1 root     root           19 2003-10-18 17:28 modules -> /etc/init.d/modules
lrwxrwxrwx    1 root     root           18 2003-10-18 17:28 net.lo -> /etc/init.d/net.lo
lrwxrwxrwx    1 root     root           20 2003-10-18 17:28 netmount -> /etc/init.d/netmount
lrwxrwxrwx    1 root     root           21 2003-10-18 17:28 rmnologin -> /etc/init.d/rmnologin
lrwxrwxrwx    1 root     root           19 2003-10-18 17:28 urandom -> /etc/init.d/urandom
  
/diskless/192.168.1.21/etc/runlevels/default:
total 0
lrwxrwxrwx    1 root     root           23 2003-10-18 17:28 consolefont -> /etc/init.d/consolefont
lrwxrwxrwx    1 root     root           19 2003-10-18 17:28 distccd -> /etc/init.d/distccd
lrwxrwxrwx    1 root     root           19 2003-10-18 17:28 keymaps -> /etc/init.d/keymaps
lrwxrwxrwx    1 root     root           17 2003-10-18 17:28 local -> /etc/init.d/local
lrwxrwxrwx    1 root     root           16 2003-10-18 17:28 sshd -> /etc/init.d/sshd
lrwxrwxrwx    1 root     root           21 2003-10-18 17:28 syslog-ng -> /etc/init.d/syslog-ng
lrwxrwxrwx    1 root     root           17 2003-10-18 17:28 vixie-cron -> /etc/init.d/vixie-cron
  
/diskless/192.168.1.21/etc/runlevels/nonetwork:
total 0
lrwxrwxrwx    1 root     root           17 2003-10-18 17:28 local -> /etc/init.d/local
  
/diskless/192.168.1.21/etc/runlevels/single:
total 0
</pre>
}}

Теперь, самое время перезагрузить slave-узлы и скрестить пальцы. Работает? Поздравляем, теперь Вы гордый обладатель бездисковой рабочей станции((й) :)

{{Migrated|originalauthors=Michael Andrews, Kristian Jerpetjoen, Sven Vermeulen, Xavier Neys}}
